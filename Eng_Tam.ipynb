{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "175d17db-8750-4e7e-a2fe-3c918e6f243d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[296, 34, 228, 1553, 42, 474]\n",
      "[132, 2089, 1498]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  11%|██████▋                                                      | 69/625 [01:30<12:12,  1.32s/it, loss=7.31]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 310\u001b[0m\n\u001b[0;32m    304\u001b[0m             loop\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m    306\u001b[0m \u001b[38;5;66;03m# Example:\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;66;03m# train_model(model, loader, epochs=5)\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtranslate\u001b[39m(model, sentence, eng_tokenizer, tam_tokenizer, max_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    313\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n",
      "Cell \u001b[1;32mIn[23], line 293\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, dataloader, epochs)\u001b[0m\n\u001b[0;32m    289\u001b[0m src, tgt_in, tgt_out \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mto(device), tgt_in\u001b[38;5;241m.\u001b[39mto(device), tgt_out\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    291\u001b[0m tgt_mask \u001b[38;5;241m=\u001b[39m generate_square_subsequent_mask(tgt_in\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m--> 293\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    295\u001b[0m output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, output\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    296\u001b[0m tgt_out \u001b[38;5;241m=\u001b[39m tgt_out\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\users\\ndr\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\users\\ndr\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[23], line 261\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, src, tgt_in, src_mask, tgt_mask)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, src, tgt_in, src_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, tgt_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    260\u001b[0m     enc_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(src, src_mask)\n\u001b[1;32m--> 261\u001b[0m     dec_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtgt_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_out(dec_out)\n",
      "File \u001b[1;32mc:\\users\\ndr\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\users\\ndr\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[23], line 248\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[1;34m(self, x, enc_output, tgt_mask, src_mask)\u001b[0m\n\u001b[0;32m    246\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_enc(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed(x))\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m--> 248\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\users\\ndr\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\users\\ndr\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[23], line 215\u001b[0m, in \u001b[0;36mDecoderBlock.forward\u001b[1;34m(self, x, enc_output, tgt_mask, src_mask)\u001b[0m\n\u001b[0;32m    212\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menc_dec_attn(x, enc_output, enc_output, src_mask))\n\u001b[0;32m    214\u001b[0m \u001b[38;5;66;03m# 3. Feed Forward\u001b[39;00m\n\u001b[1;32m--> 215\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\users\\ndr\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\users\\ndr\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[23], line 182\u001b[0m, in \u001b[0;36mAddNorm.forward\u001b[1;34m(self, x, sublayer_output)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, sublayer_output):\n\u001b[1;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43msublayer_output\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\users\\ndr\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\users\\ndr\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\users\\ndr\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\dropout.py:70\u001b[0m, in \u001b[0;36mDropout.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\ndr\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\functional.py:1425\u001b[0m, in \u001b[0;36mdropout\u001b[1;34m(input, p, training, inplace)\u001b[0m\n\u001b[0;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[0;32m   1423\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1424\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m-> 1425\u001b[0m     _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1426\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sentencepiece as spm\n",
    "df = pd.read_parquet('Downloads\\wiki_train.parquet')\n",
    "df.head()\n",
    "\n",
    "x=df['eng_Latn'].values\n",
    "y=df['tam_Taml'].values\n",
    "\n",
    "x=x[:20000]\n",
    "y=y[:20000]\n",
    "\n",
    "with open(\"tam.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for line in y:\n",
    "        f.write(str(line).strip() + \"\\n\")\n",
    "\n",
    "with open(\"eng.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for line in x:\n",
    "        f.write(str(line).strip() + \"\\n\")\n",
    "\n",
    "# English\n",
    "spm.SentencePieceTrainer.train(input='eng.txt', model_prefix='eng_tokenizer', vocab_size=8000)\n",
    "\n",
    "# Tamil\n",
    "spm.SentencePieceTrainer.train(input='tam.txt', model_prefix='tam_tokenizer', vocab_size=8000)\n",
    "\n",
    "\n",
    "# Load tokenizers\n",
    "eng_sp = spm.SentencePieceProcessor(model_file='eng_tokenizer.model')\n",
    "tam_sp = spm.SentencePieceProcessor(model_file='tam_tokenizer.model')\n",
    "\n",
    "# Encode examples\n",
    "print(eng_sp.encode(\"Let me break it down\", out_type=int))\n",
    "print(tam_sp.encode(\"நான் படிக்கிறேன்\", out_type=int))\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, eng_sentences, tam_sentences, eng_tokenizer, tam_tokenizer, max_len=50):\n",
    "        self.eng = eng_sentences\n",
    "        self.tam = tam_sentences\n",
    "        self.eng_tok = eng_tokenizer\n",
    "        self.tam_tok = tam_tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.eng)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        eng_sentence = str(self.eng[idx])\n",
    "        tam_sentence = str(self.tam[idx])\n",
    "    \n",
    "        src_ids = self.eng_tok.encode(eng_sentence, out_type=int)\n",
    "        tgt_ids = self.tam_tok.encode(tam_sentence, out_type=int)\n",
    "    \n",
    "        # Truncate\n",
    "        src_ids = src_ids[:self.max_len]\n",
    "        tgt_ids = tgt_ids[:self.max_len - 1]\n",
    "    \n",
    "        decoder_input = [1] + tgt_ids\n",
    "        decoder_target = tgt_ids + [2]\n",
    "    \n",
    "        return {\n",
    "            \"src\": torch.tensor(src_ids, dtype=torch.long),\n",
    "            \"tgt_in\": torch.tensor(decoder_input, dtype=torch.long),\n",
    "            \"tgt_out\": torch.tensor(decoder_target, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch = [item[\"src\"] for item in batch]\n",
    "    tgt_in_batch = [item[\"tgt_in\"] for item in batch]\n",
    "    tgt_out_batch = [item[\"tgt_out\"] for item in batch]\n",
    "\n",
    "    src_padded = pad_sequence(src_batch, batch_first=True, padding_value=0)\n",
    "    tgt_in_padded = pad_sequence(tgt_in_batch, batch_first=True, padding_value=0)\n",
    "    tgt_out_padded = pad_sequence(tgt_out_batch, batch_first=True, padding_value=0)\n",
    "\n",
    "    return src_padded, tgt_in_padded, tgt_out_padded\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = TranslationDataset(x, y, eng_sp, tam_sp, max_len=50)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Create [max_len, d_model] matrix\n",
    "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)  # [max_len, 1]\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2, dtype=torch.float32) * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model, dtype=torch.float32)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # [1, max_len, d_model]\n",
    "\n",
    "        self.register_buffer(\"pe\", pe)  # Safe for `.to(device)`, no optimizer step\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [batch_size, seq_len, d_model]\n",
    "        Returns:\n",
    "            x + positional encoding: same shape\n",
    "        \"\"\"\n",
    "        x = x * math.sqrt(self.d_model)  # optional scaling\n",
    "        x = x + self.pe[:, :x.size(1), :].to(x.device)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model: int, num_heads: int):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.out_linear = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        batch_size = query.size(0)\n",
    "        query_len = query.size(1)\n",
    "        key_len = key.size(1)\n",
    "\n",
    "        Q = self.q_linear(query).view(batch_size, query_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        K = self.k_linear(key).view(batch_size, key_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        V = self.v_linear(value).view(batch_size, key_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        scores = Q @ K.transpose(-2, -1) / math.sqrt(self.head_dim)\n",
    "\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "        attn_weights = torch.softmax(scores, dim=-1)\n",
    "        attn_output = attn_weights @ V\n",
    "\n",
    "        concat = attn_output.transpose(1, 2).contiguous().view(batch_size, query_len, self.d_model)\n",
    "        return self.out_linear(concat)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_ff, d_model)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class AddNorm(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer_output):\n",
    "        return self.norm(x + self.dropout(sublayer_output))\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ff = FeedForward(d_model, d_ff, dropout)\n",
    "        self.norm1 = AddNorm(d_model, dropout)\n",
    "        self.norm2 = AddNorm(d_model, dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.norm1(x, self.attn(x,x,x, mask))\n",
    "        x = self.norm2(x, self.ff(x))\n",
    "        return x\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ff = FeedForward(d_model, d_ff, dropout)\n",
    "        self.norm1 = AddNorm(d_model, dropout)\n",
    "        self.norm2 = AddNorm(d_model, dropout)\n",
    "        self.norm3 = AddNorm(d_model, dropout)\n",
    "\n",
    "    def forward(self, x, enc_output, tgt_mask=None, src_mask=None):\n",
    "        # 1. Masked self-attention (Q=K=V=x)\n",
    "        x = self.norm1(x, self.self_attn(x, x, x, tgt_mask))\n",
    "    \n",
    "        # 2. Encoder-decoder attention (Q = x, K/V = enc_output)\n",
    "        x = self.norm2(x, self.enc_dec_attn(x, enc_output, enc_output, src_mask))\n",
    "    \n",
    "        # 3. Feed Forward\n",
    "        x = self.norm3(x, self.ff(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, num_layers, num_heads, d_ff, max_len=100, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_enc = PositionalEncoding(d_model, max_len)\n",
    "        self.blocks = nn.ModuleList([\n",
    "            EncoderBlock(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.pos_enc(self.embed(x))\n",
    "        for block in self.blocks:\n",
    "            x = block(x, mask)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, num_layers, num_heads, d_ff, max_len=100, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_enc = PositionalEncoding(d_model, max_len)\n",
    "        self.blocks = nn.ModuleList([\n",
    "            DecoderBlock(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x, enc_output, tgt_mask=None, src_mask=None):\n",
    "        x = self.pos_enc(self.embed(x))\n",
    "        for block in self.blocks:\n",
    "            x = block(x, enc_output, tgt_mask, src_mask)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab, tgt_vocab, d_model=256, num_layers=4, num_heads=8, d_ff=512, dropout=0.1, max_len=100):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(src_vocab, d_model, num_layers, num_heads, d_ff, max_len, dropout)\n",
    "        self.decoder = Decoder(tgt_vocab, d_model, num_layers, num_heads, d_ff, max_len, dropout)\n",
    "        self.fc_out = nn.Linear(d_model, tgt_vocab)\n",
    "\n",
    "    def forward(self, src, tgt_in, src_mask=None, tgt_mask=None):\n",
    "        enc_out = self.encoder(src, src_mask)\n",
    "        dec_out = self.decoder(tgt_in, enc_out, tgt_mask, src_mask)\n",
    "        return self.fc_out(dec_out)\n",
    "\n",
    "\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = torch.triu(torch.ones(sz, sz), diagonal=1).bool()\n",
    "    return mask == 0  # True where allowed\n",
    "\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = Transformer(\n",
    "    src_vocab=8000, tgt_vocab=8000, d_model=256,\n",
    "    num_layers=4, num_heads=8, d_ff=512\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, dataloader, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        loop = tqdm(dataloader, desc=f\"Epoch {epoch+1}\")\n",
    "        for src, tgt_in, tgt_out in loop:\n",
    "            src, tgt_in, tgt_out = src.to(device), tgt_in.to(device), tgt_out.to(device)\n",
    "\n",
    "            tgt_mask = generate_square_subsequent_mask(tgt_in.size(1)).to(device)\n",
    "\n",
    "            output = model(src, tgt_in, src_mask=None, tgt_mask=tgt_mask)\n",
    "\n",
    "            output = output.view(-1, output.size(-1))\n",
    "            tgt_out = tgt_out.view(-1)\n",
    "\n",
    "            loss = criterion(output, tgt_out)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "# Example:\n",
    "# train_model(model, loader, epochs=5)\n",
    "\n",
    "\n",
    "train_model(model,loader,5)\n",
    "\n",
    "def translate(model, sentence, eng_tokenizer, tam_tokenizer, max_len=50, device=\"cpu\"):\n",
    "    model.eval()\n",
    "\n",
    "    # Step 1: Tokenize and encode the source sentence (English)\n",
    "    src_ids = eng_tokenizer.encode(sentence, out_type=int)[:max_len]\n",
    "    src_tensor = torch.tensor(src_ids, dtype=torch.long).unsqueeze(0).to(device)  # [1, src_len]\n",
    "\n",
    "    # Step 2: Start with <BOS> token for decoder input\n",
    "    tgt_ids = [1]  # SentencePiece default: 1 is <BOS>, 2 is <EOS>\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        tgt_tensor = torch.tensor(tgt_ids, dtype=torch.long).unsqueeze(0).to(device)  # [1, tgt_len]\n",
    "        tgt_mask = generate_square_subsequent_mask(tgt_tensor.size(1)).to(device)     # causal mask\n",
    "\n",
    "        # Step 3: Forward through the model\n",
    "        with torch.no_grad():\n",
    "            output = model(src_tensor, tgt_tensor, tgt_mask=tgt_mask)  # [1, tgt_len, vocab_size]\n",
    "\n",
    "        # Step 4: Get the next token\n",
    "        next_token = output[0, -1].argmax(-1).item()\n",
    "        if next_token == 2:  # <EOS> token\n",
    "            break\n",
    "        tgt_ids.append(next_token)\n",
    "\n",
    "    # Step 5: Decode token IDs to Tamil sentence (excluding <BOS>)\n",
    "    return tam_tokenizer.decode(tgt_ids[1:])  # skip <BOS>\n",
    "\n",
    "\n",
    "# Make sure your model is trained before calling this\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "sentence = \"Get out\"\n",
    "translated = translate(model, sentence, eng_sp, tam_sp, device=device)\n",
    "print(\"Translated:\", translated)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a42f68d-2dd6-413b-a440-5506da4c2744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English tokenization: [296, 34, 228, 1553, 42, 474]\n",
      "Tamil tokenization: [132, 2084, 1499]\n",
      "Using device: cpu\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|█████████████████████████████████████████████████████████| 625/625 [12:40<00:00,  1.22s/it, loss=4.99]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Average Loss = 6.0250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|█████████████████████████████████████████████████████████| 625/625 [12:52<00:00,  1.24s/it, loss=4.38]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Average Loss = 4.6356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|█████████████████████████████████████████████████████████| 625/625 [12:28<00:00,  1.20s/it, loss=3.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Average Loss = 3.9015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████████████████████████████████████████████████████| 625/625 [12:22<00:00,  1.19s/it, loss=3.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Average Loss = 3.3216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|█████████████████████████████████████████████████████████| 625/625 [12:37<00:00,  1.21s/it, loss=2.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Average Loss = 2.8736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|█████████████████████████████████████████████████████████| 625/625 [14:38<00:00,  1.41s/it, loss=2.37]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Average Loss = 2.5280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|█████████████████████████████████████████████████████████| 625/625 [14:19<00:00,  1.38s/it, loss=2.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Average Loss = 2.2503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|█████████████████████████████████████████████████████████| 625/625 [11:58<00:00,  1.15s/it, loss=2.04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Average Loss = 2.0180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|█████████████████████████████████████████████████████████| 625/625 [12:01<00:00,  1.15s/it, loss=1.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Average Loss = 1.8222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|████████████████████████████████████████████████████████| 625/625 [12:02<00:00,  1.16s/it, loss=1.53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Average Loss = 1.6522\n",
      "\n",
      "Testing translation...\n",
      "English: Get out\n",
      "Tamil: கெ கெட் கெட் கெட் கெட் கெட் கெட் கெட் கெட் கெட் கெட் கெட் கெட் கெட் கெட் கா கா காட் கெட் கெட் கெட் கெட் கெட் கெட் கெட் கெட் கெ\n",
      "--------------------------------------------------\n",
      "English: Hello, how are you?\n",
      "Tamil: எச்.லோ, ஐ, எவ்வாறு எவ்வாறு? எச் என்பதை? எச்? என்பது ஒரு நீங்கள் என்ன? எச் என்பதை? எச் என்பதை? எச் என்பதை? எச். எல்?, ',',',' என்றால் என்ன? எச். எல்.லோ,\n",
      "--------------------------------------------------\n",
      "English: I am learning Tamil\n",
      "Tamil: ஐ. ஐ. கற்றல் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ் தமிழ்\n",
      "--------------------------------------------------\n",
      "Model saved as 'translation_model.pth'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sentencepiece as spm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Load data\n",
    "df = pd.read_parquet('Downloads/wiki_train.parquet')  # Fixed path separator\n",
    "df.head()\n",
    "\n",
    "x = df['eng_Latn'].values\n",
    "y = df['tam_Taml'].values\n",
    "\n",
    "x = x[:20000]\n",
    "y = y[:20000]\n",
    "\n",
    "# Save training data for tokenizer training\n",
    "with open(\"tam.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for line in y:\n",
    "        if line is not None:  # Check for None values\n",
    "            f.write(str(line).strip() + \"\\n\")\n",
    "\n",
    "with open(\"eng.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for line in x:\n",
    "        if line is not None:  # Check for None values\n",
    "            f.write(str(line).strip() + \"\\n\")\n",
    "\n",
    "# Train tokenizers\n",
    "# English\n",
    "spm.SentencePieceTrainer.train(input='eng.txt', model_prefix='eng_tokenizer', vocab_size=8000)\n",
    "\n",
    "# Tamil\n",
    "spm.SentencePieceTrainer.train(input='tam.txt', model_prefix='tam_tokenizer', vocab_size=8000)\n",
    "\n",
    "# Load tokenizers\n",
    "eng_sp = spm.SentencePieceProcessor(model_file='eng_tokenizer.model')\n",
    "tam_sp = spm.SentencePieceProcessor(model_file='tam_tokenizer.model')\n",
    "\n",
    "# Test tokenizers\n",
    "print(\"English tokenization:\", eng_sp.encode(\"Let me break it down\", out_type=int))\n",
    "print(\"Tamil tokenization:\", tam_sp.encode(\"நான் படிக்கிறேன்\", out_type=int))\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, eng_sentences, tam_sentences, eng_tokenizer, tam_tokenizer, max_len=50):\n",
    "        self.eng = eng_sentences\n",
    "        self.tam = tam_sentences\n",
    "        self.eng_tok = eng_tokenizer\n",
    "        self.tam_tok = tam_tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.eng)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        eng_sentence = str(self.eng[idx]) if self.eng[idx] is not None else \"\"\n",
    "        tam_sentence = str(self.tam[idx]) if self.tam[idx] is not None else \"\"\n",
    "    \n",
    "        src_ids = self.eng_tok.encode(eng_sentence, out_type=int)\n",
    "        tgt_ids = self.tam_tok.encode(tam_sentence, out_type=int)\n",
    "    \n",
    "        # Truncate to max_len\n",
    "        src_ids = src_ids[:self.max_len]\n",
    "        tgt_ids = tgt_ids[:self.max_len - 1]  # Leave space for EOS\n",
    "    \n",
    "        # Prepare decoder input and target\n",
    "        decoder_input = [1] + tgt_ids  # BOS + target\n",
    "        decoder_target = tgt_ids + [2]  # target + EOS\n",
    "    \n",
    "        return {\n",
    "            \"src\": torch.tensor(src_ids, dtype=torch.long),\n",
    "            \"tgt_in\": torch.tensor(decoder_input, dtype=torch.long),\n",
    "            \"tgt_out\": torch.tensor(decoder_target, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch = [item[\"src\"] for item in batch]\n",
    "    tgt_in_batch = [item[\"tgt_in\"] for item in batch]\n",
    "    tgt_out_batch = [item[\"tgt_out\"] for item in batch]\n",
    "\n",
    "    src_padded = pad_sequence(src_batch, batch_first=True, padding_value=0)\n",
    "    tgt_in_padded = pad_sequence(tgt_in_batch, batch_first=True, padding_value=0)\n",
    "    tgt_out_padded = pad_sequence(tgt_out_batch, batch_first=True, padding_value=0)\n",
    "\n",
    "    return src_padded, tgt_in_padded, tgt_out_padded\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Create positional encoding matrix\n",
    "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2, dtype=torch.float32) * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model, dtype=torch.float32)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        if d_model % 2 == 1:  # Handle odd d_model\n",
    "            pe[:, 1::2] = torch.cos(position * div_term[:-1])\n",
    "        else:\n",
    "            pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        pe = pe.unsqueeze(0)  # [1, max_len, d_model]\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x * math.sqrt(self.d_model)\n",
    "        seq_len = x.size(1)\n",
    "        x = x + self.pe[:, :seq_len, :].to(x.device)\n",
    "        return x\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model: int, num_heads: int):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.out_linear = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        batch_size = query.size(0)\n",
    "        query_len = query.size(1)\n",
    "        key_len = key.size(1)\n",
    "\n",
    "        # Linear projections and reshape\n",
    "        Q = self.q_linear(query).view(batch_size, query_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        K = self.k_linear(key).view(batch_size, key_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        V = self.v_linear(value).view(batch_size, key_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        # Scaled dot-product attention\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
    "\n",
    "        if mask is not None:\n",
    "            # Expand mask to match the shape [batch_size, num_heads, query_len, key_len]\n",
    "            if mask.dim() == 2:  # [query_len, key_len]\n",
    "                mask = mask.unsqueeze(0).unsqueeze(0)  # [1, 1, query_len, key_len]\n",
    "            elif mask.dim() == 3:  # [batch_size, query_len, key_len]\n",
    "                mask = mask.unsqueeze(1)  # [batch_size, 1, query_len, key_len]\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "        attn_weights = torch.softmax(scores, dim=-1)\n",
    "        attn_output = torch.matmul(attn_weights, V)\n",
    "\n",
    "        # Concatenate heads\n",
    "        concat = attn_output.transpose(1, 2).contiguous().view(batch_size, query_len, self.d_model)\n",
    "        return self.out_linear(concat)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_ff, d_model)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class AddNorm(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer_output):\n",
    "        return self.norm(x + self.dropout(sublayer_output))\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ff = FeedForward(d_model, d_ff, dropout)\n",
    "        self.norm1 = AddNorm(d_model, dropout)\n",
    "        self.norm2 = AddNorm(d_model, dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.norm1(x, self.attn(x, x, x, mask))\n",
    "        x = self.norm2(x, self.ff(x))\n",
    "        return x\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ff = FeedForward(d_model, d_ff, dropout)\n",
    "        self.norm1 = AddNorm(d_model, dropout)\n",
    "        self.norm2 = AddNorm(d_model, dropout)\n",
    "        self.norm3 = AddNorm(d_model, dropout)\n",
    "\n",
    "    def forward(self, x, enc_output, tgt_mask=None, src_mask=None):\n",
    "        # Masked self-attention\n",
    "        x = self.norm1(x, self.self_attn(x, x, x, tgt_mask))\n",
    "        \n",
    "        # Encoder-decoder attention\n",
    "        x = self.norm2(x, self.enc_dec_attn(x, enc_output, enc_output, src_mask))\n",
    "        \n",
    "        # Feed forward\n",
    "        x = self.norm3(x, self.ff(x))\n",
    "        return x\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, num_layers, num_heads, d_ff, max_len=100, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_enc = PositionalEncoding(d_model, max_len)\n",
    "        self.blocks = nn.ModuleList([\n",
    "            EncoderBlock(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)\n",
    "        ])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.dropout(self.pos_enc(self.embed(x)))\n",
    "        for block in self.blocks:\n",
    "            x = block(x, mask)\n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, num_layers, num_heads, d_ff, max_len=100, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_enc = PositionalEncoding(d_model, max_len)\n",
    "        self.blocks = nn.ModuleList([\n",
    "            DecoderBlock(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)\n",
    "        ])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, enc_output, tgt_mask=None, src_mask=None):\n",
    "        x = self.dropout(self.pos_enc(self.embed(x)))\n",
    "        for block in self.blocks:\n",
    "            x = block(x, enc_output, tgt_mask, src_mask)\n",
    "        return x\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab, tgt_vocab, d_model=256, num_layers=4, num_heads=8, d_ff=512, dropout=0.1, max_len=100):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(src_vocab, d_model, num_layers, num_heads, d_ff, max_len, dropout)\n",
    "        self.decoder = Decoder(tgt_vocab, d_model, num_layers, num_heads, d_ff, max_len, dropout)\n",
    "        self.fc_out = nn.Linear(d_model, tgt_vocab)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, src, tgt_in, src_mask=None, tgt_mask=None):\n",
    "        enc_out = self.encoder(src, src_mask)\n",
    "        dec_out = self.decoder(tgt_in, enc_out, tgt_mask, src_mask)\n",
    "        return self.fc_out(dec_out)\n",
    "\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    \"\"\"Generate a square mask for the sequence. The masked positions are filled with 0.\"\"\"\n",
    "    mask = torch.triu(torch.ones(sz, sz), diagonal=1).bool()\n",
    "    return ~mask  # Invert: True where allowed, False where masked\n",
    "\n",
    "def create_padding_mask(seq, pad_idx=0):\n",
    "    \"\"\"Create padding mask where pad_idx positions are masked (False).\"\"\"\n",
    "    return (seq != pad_idx)\n",
    "\n",
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = TranslationDataset(x, y, eng_sp, tam_sp, max_len=50)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# Initialize model\n",
    "model = Transformer(\n",
    "    src_vocab=8000, tgt_vocab=8000, d_model=256,\n",
    "    num_layers=4, num_heads=8, d_ff=512\n",
    ").to(device)\n",
    "\n",
    "# Optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)  # Ignore padding tokens\n",
    "\n",
    "def train_model(model, dataloader, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        loop = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "        \n",
    "        for batch_idx, (src, tgt_in, tgt_out) in enumerate(loop):\n",
    "            src, tgt_in, tgt_out = src.to(device), tgt_in.to(device), tgt_out.to(device)\n",
    "\n",
    "            # Create masks\n",
    "            tgt_seq_len = tgt_in.size(1)\n",
    "            tgt_mask = generate_square_subsequent_mask(tgt_seq_len).to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            output = model(src, tgt_in, src_mask=None, tgt_mask=tgt_mask)\n",
    "\n",
    "            # Reshape for loss calculation\n",
    "            output = output.view(-1, output.size(-1))\n",
    "            tgt_out = tgt_out.view(-1)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(output, tgt_out)\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch+1}: Average Loss = {avg_loss:.4f}\")\n",
    "\n",
    "def translate(model, sentence, eng_tokenizer, tam_tokenizer, max_len=50, device=\"cpu\"):\n",
    "    model.eval()\n",
    "\n",
    "    # Tokenize source sentence\n",
    "    src_ids = eng_tokenizer.encode(sentence, out_type=int)[:max_len]\n",
    "    src_tensor = torch.tensor(src_ids, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    # Start with BOS token\n",
    "    tgt_ids = [1]  # BOS token\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_len):\n",
    "            tgt_tensor = torch.tensor(tgt_ids, dtype=torch.long).unsqueeze(0).to(device)\n",
    "            tgt_mask = generate_square_subsequent_mask(tgt_tensor.size(1)).to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(src_tensor, tgt_tensor, tgt_mask=tgt_mask)\n",
    "\n",
    "            # Get next token\n",
    "            next_token = output[0, -1].argmax(-1).item()\n",
    "            \n",
    "            if next_token == 2:  # EOS token\n",
    "                break\n",
    "                \n",
    "            tgt_ids.append(next_token)\n",
    "\n",
    "    # Decode (skip BOS token)\n",
    "    translated_text = tam_tokenizer.decode(tgt_ids[1:])\n",
    "    return translated_text\n",
    "\n",
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "train_model(model, loader, epochs=10)\n",
    "\n",
    "# Test translation\n",
    "print(\"\\nTesting translation...\")\n",
    "model.to(device)\n",
    "\n",
    "test_sentences = [\n",
    "    \"Get out\",\n",
    "    \"Hello, how are you?\",\n",
    "    \"I am learning Tamil\"\n",
    "]\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    translated = translate(model, sentence, eng_sp, tam_sp, device=device)\n",
    "    print(f\"English: {sentence}\")\n",
    "    print(f\"Tamil: {translated}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'translation_model.pth')\n",
    "print(\"Model saved as 'translation_model.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabfb4ad-29a7-44fa-9cc2-ace3fdf65505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate\n",
    "translation = translate(model, \"Good morning\", eng_tokenizer, tam_tokenizer, device=device)\n",
    "print(\"Translation:\", translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b03309a-f71c-4a59-a47d-b8bf917fc674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ஒரு கார்டர் ஒரு கார் கார்டர் என்பது கார் கார் கார் கார்டர் கார் கார் கார் கார் கார் கார்டர் கார்டர் கார் கார் கார் கார் கார் கார் கார் கார் கார் கார் கார் ஆகும், அவை நீண்ட ஓட்டுநர் நீண்ட கார் கார் கார் கார் கார் கார் கார் கார்டர்கள்'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(model,\"we are going to drive a car\", eng_sp, tam_sp, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab31185d-8b62-4efb-96e1-eb27aedf9382",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
